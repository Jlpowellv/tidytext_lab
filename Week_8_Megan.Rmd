---
title: "Week 8 Tidy Text"
author: "Megan Lin & James Powell"
date: "3/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(stringr)

library(tidyverse)
#install.packages("tidytext")
library(tidytext)
#install.packages("ggwordcloud")
library(ggwordcloud)
#install.packages("gutenbergr") 
library(gutenbergr)
#install.packages('textdata')
library(textdata)
#install.packages("striprtf")
library("striprtf")
setwd("/cloud/project")
save.image("tidytext.RData")
```

Our team will be evaluating documents from 2010-present on artificial intelligence. Megan will be researching newspapers from Asia-- specifically China Daily and the Korea Herald. Eva found articles from The Sun (England) and Business Daily (South Africa). James found articles from USA Today and The NY Times.

## Prepare the Data
First, we read in data from each source which were uploaded into separate folders in our workspace. The names of these folders matches the name of the newspapers they were pulled from. An rtf reader was used to help extract the text from these articles.
```{r echo=FALSE}
china_files <- list.files(path="/cloud/project/China Daily", pattern="*rtf", full.names=TRUE, recursive=FALSE)

korea_files <- list.files(path="/cloud/project/Korea Herald", pattern="*rtf", full.names=TRUE, recursive=FALSE)

NY_files <- list.files(path="/cloud/project/TheNewYorkTimes", pattern="*rtf", full.names=TRUE, recursive=FALSE)

US_files <- list.files(path="/cloud/project/USAToday", pattern="*rtf", full.names=TRUE, recursive=FALSE)

Africa_files <- list.files(path="/cloud/project/Business Day (South Africa)", pattern="*rtf", full.names=TRUE, recursive=FALSE)

Eng_files <- list.files(path="/cloud/project/The Sun (England)", pattern="*rtf", full.names=TRUE, recursive=FALSE)
```

## Sentiment Analysis
Next, we made a sentiment analysis helper function to help automate the analysis process.

The sentiment analysis takes in the list of files for a newspaper, then:
Iterates through each file
Extracts the data using an rtf reader & turn it into a tibble
Renames the column of data to have the name "article" for easier access
Gets the word count in the article
Use afinn, nrc, and bing sentiment analysis methods to extract sentiments from the text
Aggregate the article data so that the occurrences of each word are summed and there are no repeat words

```{r echo=FALSE, include = FALSE}
sentiment_analysis = function(files){
  afinn<-data.frame(row.names=c("word", "name", "value"))
  nrc<-data.frame(row.names=c("word", "n", "sentiment"))
  bing<-data.frame(row.names=c("word", "n", "sentiment"))
  
  for (file in files){
    data<-tibble(read_rtf(file, verbose = FALSE, ignore_tables = FALSE, check_file = TRUE))
    colnames(data) <- "article"
    data$article <- as.character(data$article)
    
    data <- data %>%
    unnest_tokens(word, article)%>%
    anti_join(stop_words)%>% 
    count(word, sort=TRUE)
  
    data_afinn <- data %>%
      inner_join(get_sentiments("afinn"))
    
    afinn <- rbind(afinn, data_afinn)
    
    data_nrc <- data %>%
      inner_join(get_sentiments("nrc"))
    nrc <- rbind(nrc, data_nrc)
    
    data_bing <- data %>%
      inner_join(get_sentiments("bing"))
    
    bing <- rbind(bing, data_bing)
  }
  agg_afinn <- afinn %>% group_by(word, value) %>% summarise(TotalCount = sum(n))
  agg_nrc <- nrc %>% group_by(word, sentiment) %>% summarise(TotalCount = sum(n))
  agg_bing <- bing %>% group_by(word, sentiment) %>% summarise(TotalCount = sum(n))
  s_list<-list(agg_afinn, agg_nrc, agg_bing)
  return (s_list)
}
```

The sentiment analysis helper function was then run on all 6 newspapers
```{r echo=FALSE, include = FALSE}
china<-sentiment_analysis(china_files)
korea<-sentiment_analysis(korea_files)
ny<-sentiment_analysis(NY_files)
us<-sentiment_analysis(US_files)
africa<-sentiment_analysis(Africa_files)
england<-sentiment_analysis(Eng_files)
```

## Sentiment Analysis Tables {.tabset}

### China Daily
```{r echo=FALSE}
china
```
### Korea Herald
```{r echo=FALSE}
korea
```
### New York Times
```{r echo=FALSE}
ny
```
### USA Today
```{r echo=FALSE}
us
```
### Business Day
```{r echo=FALSE}
africa
```
### The Sun
```{r echo=FALSE}
england
```

## Sentiment Analysis Methods {.tabset}
Each method's scoring is stored in a list so it must first be extracted before further analysis can be done. The method's are stored in the list in this order: afinn, nrc, then bing. The list must be indexed to access each of these newspaper's specific method's dataframes from earlier. As a group we decided that the combination of afinn and bing models paired better together to describe the connotations associated with artificial intelligence in a more quantitative method with a clear cut between positive and negative. While NRC was interesting in separating them into separate sentiments, we thought this combination would be more effective.

### AFINN Sentiment Analysis Conclusions
To evaluate the afinn method on these six newspapers, we multiplied the number of occurrences of a word by its positive/negative value, then averaged them to get an overall positive/negative magnitude.

The afinn average score for each newspaper is stored in a table with the first column as the newspaper name and the second as the overall average value as pictured below
```{r echo=FALSE, include = TRUE}
afinn <- data.frame(row.names = c("1", "2"))

avg_afinn<-function(ds, afinn_data, name){
  data <- afinn_data[[1]]
  value <- 0
  total <- 0
  for (i in 1:nrow(data)){
    value <- value + data$value[i] * data$TotalCount[i]
    total <- total + data$TotalCount[i]
  } 
  avg <- value / total
  entry_data <- data.frame(name, avg)

  return(rbind(entry_data, ds))
}

afinn <- avg_afinn(afinn, china, "China Daily")
afinn <- avg_afinn(afinn, korea, "Korea Herald")
afinn <- avg_afinn(afinn, africa, "Business Day (South Africa)")
afinn <- avg_afinn(afinn, england, "The Sun (England")
afinn <- avg_afinn(afinn, ny, "New York Times")
afinn <- avg_afinn(afinn, us, "USA Today")
names(afinn) <- c("Newspaper", "AverageValue")

afinn<-afinn[with(afinn, order(- AverageValue)), ]
afinn
```
Based on the afinn method, we see that China Daily has the highest average score of 0.925 which means that they likely have the most positive outlook on artificial intelligence in the future. Based on this assessment, The New York Times has the least positive outlook on artificial intelligence with an average score of 0.206.

Interestingly, all news sources throughout these chosen countries used mostly positive language when writing about artificial intelligence which can be seen by the all positive average scores.

### BING Sentiment Analysis Conclusions
To evaluate the bing method on these six newspapers, we further consolidated using the positive/negative association with each word so that the first column contained the newspaper, the second column contained positive/negative, and the third column contained the total count for the newspaper.

```{r echo=FALSE, include = TRUE}
bing<- data.frame(row.names = c("Newspaper", "Positive/Negative", "Total Count"))
avg_bing<-function(ds, bing_data, Newspaper){
  data <- bing_data[[3]]
  p_count <- 0
  n_count <- 0
  for (i in 1:nrow(data)){
    if (data$sentiment[i] == "positive"){
      p_count <- p_count + data$TotalCount[i]
    }
    else {
      n_count <- n_count + data$TotalCount[i]
    }
  }
  pos <- data.frame(Newspaper, "positive", p_count)
  neg <- c(Newspaper, "negative", n_count)
  
  entry_data <- rbind(pos, neg)
  return(rbind(ds, entry_data))
  
}
bing <- avg_bing(bing, china, "China Daily")
bing <- avg_bing(bing, korea, "Korea Herald")
bing <- avg_bing(bing, africa, "Business Day (South Africa)")
bing <- avg_bing(bing, england, "The Sun (England")
bing <- avg_bing(bing, ny, "New York Times")
bing <- avg_bing(bing, us, "USA Today")
names(bing) <- c("Newspaper", "Sentiment", "Total Count")

bing
```
Positive/Negative Ratios: China Daily(3.595), Korea Herald (2.118), USA Today (1.365), Business Day (1.352), The Sun (1.328), NY Times (1.066)

Similar to what we found with afinn, all sources had more positive language in regards to artificial intelligence than negative language (albeit it was still there). The sources with the highest positive to negative language ratio was China Daily which aligns with our results from afinn.The source that was most balanced in positive/negative language and the most negative was again the New York Times with an almost 1:1 ratio of positive to negative language. Thus, we see that even with the magnitude of positive/negative factored out, we reach a similar ranking of sources. The only switch was between USA Today and Business Day with USA Today edging out Business Day by just 0.003 in their positive negative ratios meaning Business Day used less strongly negative words or more strongly positive words which resulted in a higher score in afinn.


## TF-IDF
TF-IDF is a measure of originality  of a word by comparing the number of times a word appears in an article to the number of times the word appears in the corpus (newspaper).

A helper method to remove blank lines called "data_prep" was made to consolidate text into a 1x1 object.
```{r echo=FALSE, include = FALSE}
data_prep <- function(x,y,z){
  i <- as_tibble(t(x))
  ii <- unite(i,"text",y:z,remove = TRUE,sep = "")
}

corpus <- function(files){
  overall=data.frame()
   for (file in files){
      data<-tibble(read_rtf(file, verbose = FALSE, ignore_tables = FALSE, check_file = TRUE))
      colnames(data) <- "text"
      data$text <- as.character(data$text)
      
      overall <- bind_rows(overall, data)
   }
  return(overall)
}

```

```{r echo = FALSE, include = FALSE}
china_corpus <- corpus(china_files)
korea_corpus <- corpus(korea_files)
Africa_corpus <- corpus(Africa_files)
Eng_corpus <- corpus(Eng_files)
NY_corpus <- corpus(NY_files)
US_corpus <- corpus(US_files)
```


```{r echo = FALSE, include = FALSE}
china_corpus_prep <- data_prep(china_corpus, 'V1', 'V6257')
korea_corpus_prep <- data_prep(korea_corpus, 'V1', 'V4174')
Africa_corpus_prep <- data_prep(Africa_corpus, 'V1', 'V4820')
Eng_corpus_prep <- data_prep(Eng_corpus, 'V1', 'V5101')
NY_corpus_prep <- data_prep(NY_corpus, 'V1', 'V6601')
US_corpus_prep <- data_prep(US_corpus, 'V1','V5604')
```

Next, we ran the tf_idf code on the consolidated corpuses to get the term and in document frequencies for each word by newspaper.
```{r echo = FALSE, inclue = FALSE}
newspapers <- c("China Daily","Korea Herald","Business Day", "The Sun", "NY Times", "USA Today")
tf_idf_text <- tibble(newspapers,text=t(tibble(china_corpus_prep,korea_corpus_prep, Africa_corpus_prep,Eng_corpus_prep,NY_corpus_prep, US_corpus_prep, .name_repair =
                                               "universal")))

word_count <- tf_idf_text %>%
  unnest_tokens(word, text) %>%
  count(newspapers, word, sort = TRUE)


total_words <- word_count %>% 
  group_by(newspapers) %>% 
  summarize(total = sum(n))

inag_words <- left_join(word_count, total_words)

inag_words <- inag_words %>%
  bind_tf_idf(word, newspapers, n) %>%
  anti_join(stop_words)
```

## TF-IDF Table
```{r echo = FALSE, include = TRUE}
inag_words[with(inag_words, order(-tf_idf)), ]
```


## TF-IDF Interesting Conclusions


summary of what the tf-idf tells us