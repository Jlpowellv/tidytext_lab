---
title: "Week 8 Tidy Text"
author: "Megan Lin & James Powell"
date: "3/24/2021"
output: 
  html_document:
    toc: true
    toc_float: true
theme: minimalist
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(stringr)

library(tidyverse)
#install.packages("tidytext")
library(tidytext)
#install.packages("ggwordcloud")
library(ggwordcloud)
#install.packages("gutenbergr") 
library(gutenbergr)
#install.packages('textdata')
library(textdata)
#install.packages("striprtf")
library("striprtf")
setwd("/cloud/project")
save.image("tidytext.RData")
```

Our team will be evaluating documents from 2010-present on artificial intelligence. Megan will be researching newspapers from Asia-- specifically China Daily and the Korea Herald. Eva found articles from The Sun (England) and Business Daily (South Africa). James found articles from USA Today and The NY Times.

## Prepare the Data
First, we read in data from each source which were uploaded into separate folders in our workspace. The names of these folders matches the name of the newspapers they were pulled from. An rtf reader was used to help extract the text from these articles.
```{r echo=FALSE}
china_files <- list.files(path="/cloud/project/China Daily", pattern="*rtf", full.names=TRUE, recursive=FALSE)

korea_files <- list.files(path="/cloud/project/Korea Herald", pattern="*rtf", full.names=TRUE, recursive=FALSE)

NY_files <- list.files(path="/cloud/project/TheNewYorkTimes", pattern="*rtf", full.names=TRUE, recursive=FALSE)

US_files <- list.files(path="/cloud/project/USAToday", pattern="*rtf", full.names=TRUE, recursive=FALSE)

Africa_files <- list.files(path="/cloud/project/Business Day (South Africa)", pattern="*rtf", full.names=TRUE, recursive=FALSE)

Eng_files <- list.files(path="/cloud/project/The Sun (England)", pattern="*rtf", full.names=TRUE, recursive=FALSE)
```

## Sentiment Analysis
Next, we made a sentiment analysis helper function to help automate the analysis process.

The sentiment analysis takes in the list of files for a newspaper, then:
Iterates through each file
Extracts the data using an rtf reader & turn it into a tibble
Renames the column of data to have the name "article" for easier access
Gets the word count in the article
Use afinn, nrc, and bing sentiment analysis methods to extract sentiments from the text
Aggregate the article data so that the occurrences of each word are summed and there are no repeat words

```{r echo=FALSE, include = FALSE}
sentiment_analysis = function(files){
  afinn<-data.frame(row.names=c("word", "name", "value"))
  nrc<-data.frame(row.names=c("word", "n", "sentiment"))
  bing<-data.frame(row.names=c("word", "n", "sentiment"))
  
  for (file in files){
    data<-tibble(read_rtf(file, verbose = FALSE, ignore_tables = FALSE, check_file = TRUE))
    colnames(data) <- "article"
    data$article <- as.character(data$article)
    
    data <- data %>%
    unnest_tokens(word, article)%>%
    anti_join(stop_words)%>% 
    count(word, sort=TRUE)
  
    data_afinn <- data %>%
      inner_join(get_sentiments("afinn"))
    
    afinn <- rbind(afinn, data_afinn)
    
    data_nrc <- data %>%
      inner_join(get_sentiments("nrc"))
    nrc <- rbind(nrc, data_nrc)
    
    data_bing <- data %>%
      inner_join(get_sentiments("bing"))
    
    bing <- rbind(bing, data_bing)
  }
  agg_afinn <- afinn %>% group_by(word, value) %>% summarise(TotalCount = sum(n))
  agg_nrc <- nrc %>% group_by(word, sentiment) %>% summarise(TotalCount = sum(n))
  agg_bing <- bing %>% group_by(word, sentiment) %>% summarise(TotalCount = sum(n))
  s_list<-list(agg_afinn, agg_nrc, agg_bing)
  return (s_list)
}
```

The sentiment analysis helper function was then run on all 6 newspapers
```{r echo=FALSE, include = FALSE}
china<-sentiment_analysis(china_files)
korea<-sentiment_analysis(korea_files)
ny<-sentiment_analysis(NY_files)
us<-sentiment_analysis(US_files)
africa<-sentiment_analysis(Africa_files)
england<-sentiment_analysis(Eng_files)
```

## Sentiment Analysis Tables {.tabset}

### China Daily
```{r echo=FALSE}
china
```
### Korea Herald
```{r echo=FALSE}
korea
```
### New York Times
```{r echo=FALSE}
ny
```
### USA Today
```{r echo=FALSE}
us
```
### Business Day
```{r echo=FALSE}
africa
```
### The Sun
```{r echo=FALSE}
england
```

## Sentiment Analysis Methods {.tabset}
Each method's scoring is stored in a list so it must first be extracted before further analysis can be done. The method's are stored in the list in this order: afinn, nrc, then bing. The list must be indexed to access each of these newspaper's specific method's dataframes from earlier. As a group we decided that the combination of afinn and bing models paired better together to describe the connotations associated with artificial intelligence in a more quantitative method with a clear cut between positive and negative. While NRC was interesting in separating them into separate sentiments, we thought this combination would be more effective.

### AFINN Sentiment Analysis Conclusions
To evaluate the afinn method on these six newspapers, we multiplied the number of occurrences of a word by its positive/negative value, then averaged them to get an overall positive/negative magnitude.

The afinn average score for each newspaper is stored in a table with the first column as the newspaper name and the second as the overall average value as pictured below
```{r echo=FALSE, include = TRUE}
afinn <- data.frame(row.names = c("1", "2"))

avg_afinn<-function(ds, afinn_data, name){
  data <- afinn_data[[1]]
  value <- 0
  total <- 0
  for (i in 1:nrow(data)){
    value <- value + data$value[i] * data$TotalCount[i]
    total <- total + data$TotalCount[i]
  } 
  avg <- value / total
  entry_data <- data.frame(name, avg)

  return(rbind(entry_data, ds))
}

afinn <- avg_afinn(afinn, china, "China Daily")
afinn <- avg_afinn(afinn, korea, "Korea Herald")
afinn <- avg_afinn(afinn, africa, "Business Day (South Africa)")
afinn <- avg_afinn(afinn, england, "The Sun (England")
afinn <- avg_afinn(afinn, ny, "New York Times")
afinn <- avg_afinn(afinn, us, "USA Today")
names(afinn) <- c("Newspaper", "AverageValue")

afinn<-afinn[with(afinn, order(- AverageValue)), ]
afinn
```
Based on the afinn method, we see that China Daily has the highest average score of 0.925 which means that they likely have the most positive outlook on artificial intelligence in the future. Based on this assessment, The New York Times has the least positive outlook on artificial intelligence with an average score of 0.206.

Interestingly, all news sources throughout these chosen countries used mostly positive language when writing about artificial intelligence which can be seen by the all positive average scores.

### BING Sentiment Analysis Conclusions
To evaluate the bing method on these six newspapers, we further consolidated using the positive/negative association with each word so that the first column contained the newspaper, the second column contained positive/negative, and the third column contained the total count for the newspaper.

```{r echo=FALSE, include = TRUE}
bing<- data.frame(row.names = c("Newspaper", "Positive/Negative", "Total Count"))
avg_bing<-function(ds, bing_data, Newspaper){
  data <- bing_data[[3]]
  p_count <- 0
  n_count <- 0
  for (i in 1:nrow(data)){
    if (data$sentiment[i] == "positive"){
      p_count <- p_count + data$TotalCount[i]
    }
    else {
      n_count <- n_count + data$TotalCount[i]
    }
  }
  pos <- data.frame(Newspaper, "positive", p_count)
  neg <- c(Newspaper, "negative", n_count)
  
  entry_data <- rbind(pos, neg)
  return(rbind(ds, entry_data))
  
}
bing <- avg_bing(bing, china, "China Daily")
bing <- avg_bing(bing, korea, "Korea Herald")
bing <- avg_bing(bing, africa, "Business Day (South Africa)")
bing <- avg_bing(bing, england, "The Sun (England")
bing <- avg_bing(bing, ny, "New York Times")
bing <- avg_bing(bing, us, "USA Today")
names(bing) <- c("Newspaper", "Sentiment", "Total Count")

bing
```
Positive/Negative Ratios: China Daily(3.595), Korea Herald (2.118), USA Today (1.365), Business Day (1.352), The Sun (1.328), NY Times (1.066)

Similar to what we found with afinn, all sources had more positive language in regards to artificial intelligence than negative language (albeit it was still there). The sources with the highest positive to negative language ratio was China Daily which aligns with our results from afinn.The source that was most balanced in positive/negative language and the most negative was again the New York Times with an almost 1:1 ratio of positive to negative language. Thus, we see that even with the magnitude of positive/negative factored out, we reach a similar ranking of sources. The only switch was between USA Today and Business Day with USA Today edging out Business Day by just 0.003 in their positive negative ratios meaning Business Day used less strongly negative words or more strongly positive words which resulted in a higher score in afinn.


## TF-IDF
TF-IDF is a measure of originality  of a word by comparing the number of times a word appears in an article to the number of times the word appears in the corpus (newspaper).

A helper method to remove blank lines called "data_prep" was made to consolidate text into a 1x1 object.
```{r echo=FALSE, include = FALSE}
data_prep <- function(x,y,z){
  i <- as_tibble(t(x))
  ii <- unite(i,"text",y:z,remove = TRUE,sep = "")
}

corpus <- function(files){
  overall=data.frame()
   for (file in files){
      data<-tibble(read_rtf(file, verbose = FALSE, ignore_tables = FALSE, check_file = TRUE))
      colnames(data) <- "text"
      data$text <- as.character(data$text)
      
      overall <- bind_rows(overall, data)
   }
  return(overall)
}

```

```{r echo = FALSE, include = FALSE}
china_corpus <- corpus(china_files)
korea_corpus <- corpus(korea_files)
Africa_corpus <- corpus(Africa_files)
Eng_corpus <- corpus(Eng_files)
NY_corpus <- corpus(NY_files)
US_corpus <- corpus(US_files)
```


```{r echo = FALSE, include = FALSE}
china_corpus_prep <- data_prep(china_corpus, 'V1', 'V6257')
korea_corpus_prep <- data_prep(korea_corpus, 'V1', 'V4174')
Africa_corpus_prep <- data_prep(Africa_corpus, 'V1', 'V4820')
Eng_corpus_prep <- data_prep(Eng_corpus, 'V1', 'V5101')
NY_corpus_prep <- data_prep(NY_corpus, 'V1', 'V6601')
US_corpus_prep <- data_prep(US_corpus, 'V1','V5604')
```

Next, we ran the tf_idf code on the consolidated corpuses to get the term and in document frequencies for each word by newspaper.
```{r echo = FALSE, inclue = FALSE}
newspapers <- c("China Daily","Korea Herald","Business Day", "The Sun", "NY Times", "USA Today")
tf_idf_text <- tibble(newspapers,text=t(tibble(china_corpus_prep,korea_corpus_prep, Africa_corpus_prep,Eng_corpus_prep,NY_corpus_prep, US_corpus_prep, .name_repair =
                                               "universal")))

word_count <- tf_idf_text %>%
  unnest_tokens(word, text) %>%
  count(newspapers, word, sort = TRUE)


total_words <- word_count %>% 
  group_by(newspapers) %>% 
  summarize(total = sum(n))

inag_words <- left_join(word_count, total_words)

inag_words <- inag_words %>%
  bind_tf_idf(word, newspapers, n) %>%
  anti_join(stop_words)
```

## TF-IDF Table
Once we consildated the corpuses, this was our tf_idf table sorted in descending tf_idf values.
```{r echo = FALSE, include = TRUE}
inag_words[with(inag_words, order(-tf_idf)), ]
```


## TF-IDF Interesting Conclusions
Simply put, the tf-idf infrastructure needs some major extra layers of filtering as most of the results that we got feel like complete gibberish. However, when inspected there are few commonalities within the data we got. 

A lot of the words with higher tf-idf values, regardless of newspaper, are companies that are the top technology companies such as: Spotify, Kakao, Genie, Amazon’s Alexa,
Google Pixel, Cortana, and Samsung. 

As for the differences between the individual newspapers, there are many-- some of them more interesting than others. 

For example, USA Today talks about the Avengers with high-rated words like Avengers and Thor. This makes sense  because of the focus on AI technology through characters like Iron Man to create a more futuristic, modern storyline. In addition, Vision, one of their characters that just got their own show and is a focal point for many people, is portrayed as a very advanced form of AI.

Business Day is a newspaper from South Africa and has a less Hollywood-specific focus, instead having words related to resources/nature such as wildlife, ivory, metals, and trafficking, rated higher. We think this indicated a more practical standpoint that could be focused on industrialization or something similar. 

This productive focus continues when looking at the China Daily, which has a more business/economics focus where words such as antibiotic, and Nasdaq are near the top of the list.

The Sun (England) seems to pair artificial intelligence with politics & defense as shown by the high rating of Boris Johnson’s name, and the word “defense”.

The NY Times similarly uses a lot of words that insinuate international practicality impacts such as China, FBI, Putin, and CIA. 

Lastly the Korea Herald has a similar high focus on technology companies like Samsung, but mainly also pairs AI with more music/social media platforms like Genie and Kakao which differentiates from other countries' more practical/political/economically focused associations.

## Limitations
Within this data there are many limitations.

First and foremost, we arbitrarily picked 100 articles from each source within the specified timeline if they had a hit on the topic of AI. However, these first 100 we found could be skewed in a specific way such as USA Today's focus on the Avengers.

Secondly, because many of these newspapers were pulled from other countries, it was difficult to make sense of some of the more commonly used words without background knowledge. For example, with the Korea Herald's list of top tf_idf words, words like "genie" or "kakao" would not have made sense without a previous background knowledge. We did not have a similar background in other countries like South Africa, England, or China so it was a bit more difficult to draw conclusions.

Third, a natural limitation of sentiment analysis is not being able to create a rating for these words in context to the words around it. Quoting another source's strongly worded criticisms or praise in our method are interpreted as the source's own interpretation even if they may be neutral or opposed to the quote's opinion. Overall, this was an issue we addressed in class of not being able to draw conclusions based on the overall context of the article, just on the word count frequency.

## Next Steps
Next, we would want to expand our dataset to include at least 3 newspapers from every region around the world (not necessarily each continent as some are larger than others). We could also further our search by looking at specific facets of AI to see how Deep Learning, IoT, Robotics, etc. individually are talked about by news sources around the world.